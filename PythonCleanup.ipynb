{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopy\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import gitdir\n",
    "from geopy.geocoders import Nominatim\n",
    "locator = Nominatim(user_agent=\"myGeocoder\")\n",
    "import IPython\n",
    "import svn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: .gitignore\n",
      "Downloaded: 01-22-2020.csv\n",
      "Downloaded: 01-23-2020.csv\n",
      "Downloaded: 01-24-2020.csv\n",
      "Downloaded: 01-25-2020.csv\n",
      "Downloaded: 01-26-2020.csv\n",
      "Downloaded: 01-27-2020.csv\n",
      "Downloaded: 01-28-2020.csv\n",
      "Downloaded: 01-29-2020.csv\n",
      "Downloaded: 01-30-2020.csv\n",
      "Downloaded: 01-31-2020.csv\n",
      "Downloaded: 02-01-2020.csv\n",
      "Downloaded: 02-02-2020.csv\n",
      "Downloaded: 02-03-2020.csv\n",
      "Downloaded: 02-04-2020.csv\n",
      "Downloaded: 02-05-2020.csv\n",
      "Downloaded: 02-06-2020.csv\n",
      "Downloaded: 02-07-2020.csv\n",
      "Downloaded: 02-08-2020.csv\n",
      "Downloaded: 02-09-2020.csv\n",
      "Downloaded: 02-10-2020.csv\n",
      "Downloaded: 02-11-2020.csv\n",
      "Downloaded: 02-12-2020.csv\n",
      "Downloaded: 02-13-2020.csv\n",
      "Downloaded: 02-14-2020.csv\n",
      "Downloaded: 02-15-2020.csv\n",
      "Downloaded: 02-16-2020.csv\n",
      "Downloaded: 02-17-2020.csv\n",
      "Downloaded: 02-18-2020.csv\n",
      "Downloaded: 02-19-2020.csv\n",
      "Downloaded: 02-20-2020.csv\n",
      "Downloaded: 02-21-2020.csv\n",
      "Downloaded: 02-22-2020.csv\n",
      "Downloaded: 02-23-2020.csv\n",
      "Downloaded: 02-24-2020.csv\n",
      "Downloaded: 02-25-2020.csv\n",
      "Downloaded: 02-26-2020.csv\n",
      "Downloaded: 02-27-2020.csv\n",
      "Downloaded: 02-28-2020.csv\n",
      "Downloaded: 02-29-2020.csv\n",
      "Downloaded: 03-01-2020.csv\n",
      "Downloaded: 03-02-2020.csv\n",
      "Downloaded: 03-03-2020.csv\n",
      "Downloaded: 03-04-2020.csv\n",
      "Downloaded: 03-05-2020.csv\n",
      "Downloaded: 03-06-2020.csv\n",
      "Downloaded: 03-07-2020.csv\n",
      "Downloaded: 03-08-2020.csv\n",
      "Downloaded: README.md\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\pxppa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\users\\pxppa\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\pxppa\\AppData\\Local\\Programs\\Python\\Python36\\Scripts\\gitdir.exe\\__main__.py\", line 5, in <module>\n",
      "  File \"c:\\users\\pxppa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gitdir\\__main__.py\", line 3, in <module>\n",
      "    main()\n",
      "  File \"c:\\users\\pxppa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gitdir\\gitdir.py\", line 152, in main\n",
      "    print_text(\"\\u2714 Download complete\", \"green\", in_place=True)\n",
      "  File \"c:\\users\\pxppa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gitdir\\gitdir.py\", line 30, in print_text\n",
      "    print(COLOR_NAME_TO_CODE[color] + text + Style.RESET_ALL, **kwargs)\n",
      "  File \"c:\\users\\pxppa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\colorama\\ansitowin32.py\", line 41, in write\n",
      "    self.__convertor.write(text)\n",
      "  File \"c:\\users\\pxppa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\colorama\\ansitowin32.py\", line 162, in write\n",
      "    self.write_and_convert(text)\n",
      "  File \"c:\\users\\pxppa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\colorama\\ansitowin32.py\", line 187, in write_and_convert\n",
      "    self.write_plain_text(text, cursor, start)\n",
      "  File \"c:\\users\\pxppa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\colorama\\ansitowin32.py\", line 195, in write_plain_text\n",
      "    self.wrapped.write(text[start:end])\n",
      "  File \"c:\\users\\pxppa\\appdata\\local\\programs\\python\\python36\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\u2714' in position 0: character maps to <undefined>\n"
     ]
    }
   ],
   "source": [
    "!gitdir https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirmed         float64\n",
      "Country/Region     object\n",
      "Day                object\n",
      "Deaths            float64\n",
      "Last Update        object\n",
      "Latitude          float64\n",
      "Longitude         float64\n",
      "Month              object\n",
      "Province/State     object\n",
      "Recovered         float64\n",
      "Year               object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pxppa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\pxppa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\pxppa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py:2540: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Day</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Month</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Year</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>China</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>01</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>35.000074</td>\n",
       "      <td>104.999927</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>China</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/22/2020 17:00</td>\n",
       "      <td>01</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>35.000074</td>\n",
       "      <td>104.999927</td>\n",
       "      <td>2020-01-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Confirmed Country/Region Day  Deaths      Last Update Month Province/State  \\\n",
       "0        1.0          China  22     NaN  1/22/2020 17:00    01          Anhui   \n",
       "1       14.0          China  22     NaN  1/22/2020 17:00    01        Beijing   \n",
       "\n",
       "   Recovered  Year   latitude   longitude       Date  \n",
       "0        NaN  2020  35.000074  104.999927 2020-01-22  \n",
       "1        NaN  2020  35.000074  104.999927 2020-01-22  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloade latest files\n",
    "#!gitdir https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports\n",
    "\n",
    "# Parse out MDY from filenames, iterate and append all files.\n",
    "filenames = []\n",
    "os.chdir(\"C:/Users/pxppa/OneDrive/Documents/PowerBI Projects/Corona Virus/csse_covid_19_data/csse_covid_19_daily_reports\")\n",
    "\n",
    "for file in glob.glob('*.csv'):\n",
    "    month, day, year = file.split('.')[0].split('-') \n",
    "    combined = (pd.read_csv(file).assign(Month=month, Day=day, Year=year))\n",
    "    filenames.append(combined)\n",
    "    \n",
    "combined = pd.concat(filenames)\n",
    "\n",
    "#Show me the datatypes\n",
    "datatypes = combined.dtypes\n",
    "print(datatypes)\n",
    "\n",
    "#Delete useless columns -- aka, not persisting columns\n",
    "del combined['Latitude']\n",
    "del combined['Longitude']\n",
    "\n",
    "# Change Mainland China to China -- geocoding bugs out\n",
    "combined.loc[(combined['Country/Region'] == 'Mainland China'),'Country/Region' ] = 'China'\n",
    "\n",
    "# Keep only distinct countries/regions\n",
    "Temp = combined.drop_duplicates([\"Country/Region\"].copy())\n",
    "\n",
    "# 1 - conveneint function to delay between geocoding calls\n",
    "geocode = RateLimiter(locator.geocode, min_delay_seconds=1)\n",
    "\n",
    "# 2- - create location column\n",
    "Temp['location'] = Temp['Country/Region'].apply(geocode)\n",
    "\n",
    "# 3 - create longitude, laatitude and altitude from location column (returns tuple)\n",
    "Temp['point'] = Temp['location'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "\n",
    "# 4 - split point column into latitude, longitude and altitude columns\n",
    "Temp[['latitude', 'longitude', 'altitude']] = pd.DataFrame(Temp['point'].tolist(), index=Temp.index)\n",
    "\n",
    "# Select only subset of columns\n",
    "Temp1 = Temp[['Country/Region','latitude','longitude']]\n",
    "\n",
    "# Left join to original dataframe\n",
    "combined = combined.merge(Temp1, left_on='Country/Region', right_on='Country/Region', how='left')\n",
    "\n",
    "# Date field\n",
    "combined['Date'] = pd.to_datetime(combined[['Year', 'Month', 'Day']])\n",
    "\n",
    "# Create new dataframe - for joining purposes\n",
    "joiner = combined.copy()\n",
    "\n",
    "# Create an offset date variable so that I may calculate the daily numbers, rather than cumulative\n",
    "joiner['Date offset'] = joiner['Date'] + pd.Timedelta(days=1)\n",
    "\n",
    "# Rename my helper columns\n",
    "joiner.rename(columns={'Confirmed': 'Confirmed offset'\n",
    "                       , 'Deaths': 'Deaths offset'\n",
    "                       , 'Recovered': 'Recovered offset'}\n",
    "                       , inplace=True)\n",
    "\n",
    "# Only use the subset of columns\n",
    "joiner = joiner[['Province/State'\n",
    "                 ,'Country/Region'\n",
    "                 ,'Confirmed offset'\n",
    "                 ,'Recovered offset'\n",
    "                 ,'Deaths offset'\n",
    "                 ,'Date offset']].copy()\n",
    "\n",
    "# Left join to my master data using province, region and date -- but for date, match to the offset\n",
    "Final_combined = pd.merge(combined\n",
    "                           ,joiner\n",
    "                           ,left_on=['Province/State', 'Country/Region','Date']\n",
    "                           ,right_on=['Province/State', 'Country/Region','Date offset']\n",
    "                          ,how='left'\n",
    "                           )\n",
    "\n",
    "# Calculate the daily numbers\n",
    "Final_combined['Confirmed Daily'] = Final_combined['Confirmed'] - Final_combined['Confirmed offset']\n",
    "Final_combined['Dead Daily'] = Final_combined['Deaths'] - Final_combined['Deaths offset']\n",
    "Final_combined['Recovered Daily'] = Final_combined['Recovered'] - Final_combined['Recovered offset']\n",
    "\n",
    "# Delete -now- useless columns\n",
    "del Final_combined['Confirmed offset']\n",
    "del Final_combined['Deaths offset']\n",
    "del Final_combined['Recovered offset']\n",
    "del Final_combined['Date offset']\n",
    "\n",
    "# Export dataset\n",
    "os.chdir(\"C:/Users/pxppa/OneDrive/Documents/PowerBI Projects/Corona Virus\")\n",
    "Final_combined.to_csv(\"Final Dataset/combined.csv\")\n",
    "\n",
    "combined.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
